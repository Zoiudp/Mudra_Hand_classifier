{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_PositionX</th>\n",
       "      <th>R_PositionY</th>\n",
       "      <th>R_PositionZ</th>\n",
       "      <th>R_RotationX</th>\n",
       "      <th>R_RotationY</th>\n",
       "      <th>R_RotationZ</th>\n",
       "      <th>R_RotationW</th>\n",
       "      <th>R_CurlIndex</th>\n",
       "      <th>R_CurlMiddle</th>\n",
       "      <th>R_CurlRing</th>\n",
       "      <th>...</th>\n",
       "      <th>L_RotationX</th>\n",
       "      <th>L_RotationY</th>\n",
       "      <th>L_RotationZ</th>\n",
       "      <th>L_RotationW</th>\n",
       "      <th>L_CurlIndex</th>\n",
       "      <th>L_CurlMiddle</th>\n",
       "      <th>L_CurlRing</th>\n",
       "      <th>L_CurlPinky</th>\n",
       "      <th>L_CurlThumb</th>\n",
       "      <th>Mudra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.471615</td>\n",
       "      <td>0.730263</td>\n",
       "      <td>0.952604</td>\n",
       "      <td>0.165737</td>\n",
       "      <td>0.443052</td>\n",
       "      <td>0.580202</td>\n",
       "      <td>0.731189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159486</td>\n",
       "      <td>0.548348</td>\n",
       "      <td>0.438654</td>\n",
       "      <td>0.739459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087998</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.466468</td>\n",
       "      <td>0.728169</td>\n",
       "      <td>0.959959</td>\n",
       "      <td>0.165396</td>\n",
       "      <td>0.454049</td>\n",
       "      <td>0.557253</td>\n",
       "      <td>0.733180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158458</td>\n",
       "      <td>0.551898</td>\n",
       "      <td>0.468558</td>\n",
       "      <td>0.740608</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.120933</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.463946</td>\n",
       "      <td>0.730463</td>\n",
       "      <td>0.961642</td>\n",
       "      <td>0.163535</td>\n",
       "      <td>0.453341</td>\n",
       "      <td>0.554497</td>\n",
       "      <td>0.730352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160713</td>\n",
       "      <td>0.541567</td>\n",
       "      <td>0.474051</td>\n",
       "      <td>0.745710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.453614</td>\n",
       "      <td>0.733241</td>\n",
       "      <td>0.959451</td>\n",
       "      <td>0.158962</td>\n",
       "      <td>0.451345</td>\n",
       "      <td>0.564089</td>\n",
       "      <td>0.720615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158216</td>\n",
       "      <td>0.541734</td>\n",
       "      <td>0.474162</td>\n",
       "      <td>0.741350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135019</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.452623</td>\n",
       "      <td>0.733653</td>\n",
       "      <td>0.958260</td>\n",
       "      <td>0.156610</td>\n",
       "      <td>0.448896</td>\n",
       "      <td>0.573692</td>\n",
       "      <td>0.714630</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153730</td>\n",
       "      <td>0.551971</td>\n",
       "      <td>0.471711</td>\n",
       "      <td>0.732438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117391</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   R_PositionX  R_PositionY  R_PositionZ  R_RotationX  R_RotationY  \\\n",
       "0     0.471615     0.730263     0.952604     0.165737     0.443052   \n",
       "1     0.466468     0.728169     0.959959     0.165396     0.454049   \n",
       "2     0.463946     0.730463     0.961642     0.163535     0.453341   \n",
       "3     0.453614     0.733241     0.959451     0.158962     0.451345   \n",
       "4     0.452623     0.733653     0.958260     0.156610     0.448896   \n",
       "\n",
       "   R_RotationZ  R_RotationW  R_CurlIndex  R_CurlMiddle  R_CurlRing  ...  \\\n",
       "0     0.580202     0.731189          0.0           0.0         0.0  ...   \n",
       "1     0.557253     0.733180          0.0           0.0         0.0  ...   \n",
       "2     0.554497     0.730352          0.0           0.0         0.0  ...   \n",
       "3     0.564089     0.720615          0.0           0.0         0.0  ...   \n",
       "4     0.573692     0.714630          0.0           0.0         0.0  ...   \n",
       "\n",
       "   L_RotationX  L_RotationY  L_RotationZ  L_RotationW  L_CurlIndex  \\\n",
       "0     0.159486     0.548348     0.438654     0.739459          0.0   \n",
       "1     0.158458     0.551898     0.468558     0.740608          0.0   \n",
       "2     0.160713     0.541567     0.474051     0.745710          0.0   \n",
       "3     0.158216     0.541734     0.474162     0.741350          0.0   \n",
       "4     0.153730     0.551971     0.471711     0.732438          0.0   \n",
       "\n",
       "   L_CurlMiddle  L_CurlRing  L_CurlPinky  L_CurlThumb  Mudra  \n",
       "0           0.0         0.0          0.0     0.087998      1  \n",
       "1           0.0         0.0          0.0     0.120933      1  \n",
       "2           0.0         0.0          0.0     0.131379      1  \n",
       "3           0.0         0.0          0.0     0.135019      1  \n",
       "4           0.0         0.0          0.0     0.117391      1  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo\n",
    "file_path = \"combined_data_with_classification.csv\"\n",
    "\n",
    "# Carregar o dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Exibir as primeiras linhas para análise\n",
    "df.head()\n",
    "# Remover colunas irrelevantes\n",
    "df_cleaned = df.drop(columns=['Time', 'Source'])\n",
    "\n",
    "# Separar entrada (variáveis de movimento) e saída (Mudra)\n",
    "X = df_cleaned.drop(columns=['Mudra'])\n",
    "y = df_cleaned['Mudra']\n",
    "\n",
    "# Normalizar as variáveis de movimento\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Codificar os Mudras como tokens numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Converter para DataFrame novamente\n",
    "df_processed = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_processed['Mudra'] = y_encoded\n",
    "\n",
    "# Exibir amostras dos dados processados\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31992, 10, 24), (31992, 10))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Definir tamanho da sequência\n",
    "seq_length = 10\n",
    "\n",
    "# Converter DataFrame para arrays\n",
    "X_array = df_processed.drop(columns=['Mudra']).values\n",
    "y_array = df_processed['Mudra'].values\n",
    "\n",
    "# Criar sequências de entrada e saída\n",
    "X_seq = []\n",
    "y_seq = []\n",
    "\n",
    "for i in range(len(X_array) - seq_length + 1):\n",
    "    X_seq.append(X_array[i:i + seq_length])\n",
    "    y_seq.append(y_array[i:i + seq_length])\n",
    "\n",
    "# Converter para arrays numpy\n",
    "X_seq = np.array(X_seq)\n",
    "y_seq = np.array(y_seq)\n",
    "\n",
    "# Exibir forma das sequências criadas\n",
    "X_seq.shape, y_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
       "│                     │                   │            │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">845</span> │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m24\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m1,600\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m66,368\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
       "│                     │                   │            │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m8,256\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m8,256\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m13\u001b[0m)    │        \u001b[38;5;34m845\u001b[0m │ layer_normalizat… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,845</span> (659.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m168,845\u001b[0m (659.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">168,845</span> (659.55 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m168,845\u001b[0m (659.55 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, Add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "\n",
    "\n",
    "\n",
    "# Parâmetros do modelo\n",
    "input_dim = 24  # Número de variáveis de movimento\n",
    "seq_length = 10  # Número de frames por sequência\n",
    "num_classes = len(label_encoder.classes_)  # Número de Mudras únicos\n",
    "embed_dim = 64  # Dimensão do embedding\n",
    "num_heads = 4  # Número de cabeças de atenção\n",
    "ff_dim = 128  # Dimensão da feed-forward network\n",
    "dropout_rate = 0.1  # Taxa de dropout\n",
    "\n",
    "# Camada Transformer Encoder\n",
    "def transformer_encoder(inputs, embed_dim, num_heads, ff_dim, dropout_rate):\n",
    "    # Multi-Head Attention\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
    "    attention_output = Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = Add()([inputs, attention_output])\n",
    "    attention_output = LayerNormalization()(attention_output)\n",
    "    \n",
    "    # Feed-forward network\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(attention_output)\n",
    "    ff_output = Dense(embed_dim)(ff_output)\n",
    "    ff_output = Dropout(dropout_rate)(ff_output)\n",
    "    ff_output = Add()([attention_output, ff_output])\n",
    "    return LayerNormalization()(ff_output)\n",
    "\n",
    "# Definição do modelo\n",
    "inputs = Input(shape=(seq_length, input_dim))\n",
    "x = Dense(embed_dim)(inputs)  # Embedding inicial\n",
    "\n",
    "# Adicionar camadas Transformer Encoder\n",
    "for _ in range(2):  # Duas camadas\n",
    "    x = transformer_encoder(x, embed_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "# Camada de saída para previsão de Mudras (softmax para classificação)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "# Criar modelo\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)  # Clip gradients\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Exibir resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">45,888</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,368</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">45,888</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_15          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ add_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">845</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m13\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m896\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m66,368\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m24\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m45,888\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m8,256\u001b[0m │ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_10          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_6 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m66,368\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_12          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m45,888\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_8 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │      \u001b[38;5;34m8,320\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m8,256\u001b[0m │ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_15          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_9 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ layer_normalizat… │\n",
       "│                     │                   │            │ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │        \u001b[38;5;34m128\u001b[0m │ add_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │      \u001b[38;5;34m4,160\u001b[0m │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ leaky_re_lu         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m13\u001b[0m)    │        \u001b[38;5;34m845\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,333</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m264,333\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">264,333</span> (1.01 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m264,333\u001b[0m (1.01 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Camada Transformer Decoder\n",
    "def transformer_decoder(inputs, encoder_outputs, embed_dim, num_heads, ff_dim, dropout_rate):\n",
    "    # Masked Multi-Head Attention (auto-atendimento dentro do decoder)\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(inputs, inputs)\n",
    "    attention_output = Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = Add()([inputs, attention_output])\n",
    "    attention_output = LayerNormalization()(attention_output)\n",
    "\n",
    "    # Cross-Attention (atende aos outputs do Encoder)\n",
    "    cross_attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)(\n",
    "        attention_output, encoder_outputs\n",
    "    )\n",
    "    cross_attention_output = Dropout(dropout_rate)(cross_attention_output)\n",
    "    cross_attention_output = Add()([attention_output, cross_attention_output])\n",
    "    cross_attention_output = LayerNormalization()(cross_attention_output)\n",
    "\n",
    "    # Feed-forward network\n",
    "    ff_output = Dense(ff_dim, activation=\"relu\")(cross_attention_output)\n",
    "    ff_output = Dense(embed_dim)(ff_output)\n",
    "    ff_output = Dropout(dropout_rate)(ff_output)\n",
    "    ff_output = Add()([cross_attention_output, ff_output])\n",
    "    return LayerNormalization()(ff_output)\n",
    "\n",
    "# Entrada do Decoder\n",
    "decoder_inputs = Input(shape=(seq_length, num_classes))  # Sequência de Mudras (one-hot encoded)\n",
    "x = Dense(embed_dim)(decoder_inputs)  # Embedding inicial\n",
    "\n",
    "# Adicionar camadas Transformer Decoder\n",
    "for _ in range(2):  # Duas camadas\n",
    "    x = transformer_decoder(x, encoder_outputs=inputs, embed_dim=embed_dim, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "# Camada final de previsão de Mudras\n",
    "decoder_outputs = Dense(64)(x)\n",
    "decoder_outputs = LeakyReLU(alpha=0.1)(decoder_outputs)  # Replace ReLU with LeakyReLU\n",
    "decoder_outputs = Dense(num_classes, activation=\"softmax\")(decoder_outputs)\n",
    "# Criar modelo Encoder-Decoder\n",
    "model = Model([inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0001, clipnorm=1.0)  # Clip gradients\n",
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "# Exibir resumo do modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59 0\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Separar os dados em treino e teste (80% treino, 20% teste)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42)\n",
    "\n",
    "# Converter os rótulos para one-hot encoding para o decoder\n",
    "y_train_one_hot = to_categorical(y_train, num_classes=num_classes)\n",
    "y_test_one_hot = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "# Criar deslocamento nos rótulos do decoder para \"teacher forcing\"\n",
    "decoder_input_train = np.zeros_like(y_train_one_hot)\n",
    "decoder_input_train[:, 1:, :] = y_train_one_hot[:, :-1, :]  # Desloca para frente\n",
    "\n",
    "decoder_input_test = np.zeros_like(y_test_one_hot)\n",
    "decoder_input_test[:, 1:, :] = y_test_one_hot[:, :-1, :]\n",
    "\n",
    "\n",
    "print(np.isnan(X_train).sum(), np.isnan(y_train).sum())  # Check for NaNs\n",
    "print(np.isinf(X_train).sum(), np.isinf(y_train).sum())  # Check for Infs\n",
    "X_train = np.nan_to_num(X_train)\n",
    "y_train = np.nan_to_num(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Definir callbacks\n",
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3)\n",
    "\n",
    "# Configuração dos hiperparâmetros\n",
    "batch_size = 64\n",
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float4_e2m1fn'\n",
      "Epoch 1/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 32ms/step - accuracy: 0.8369 - loss: 0.6760 - val_accuracy: 0.9980 - val_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.9976 - loss: 0.0272 - val_accuracy: 0.9979 - val_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - accuracy: 0.9978 - loss: 0.0162 - val_accuracy: 0.9979 - val_loss: nan - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - accuracy: 0.9976 - loss: 0.0137 - val_accuracy: 0.9979 - val_loss: nan - learning_rate: 5.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 33ms/step - accuracy: 0.9973 - loss: 0.0133 - val_accuracy: 0.9979 - val_loss: nan - learning_rate: 5.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 32ms/step - accuracy: 0.9977 - loss: 0.0109 - val_accuracy: 0.9980 - val_loss: nan - learning_rate: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(\n",
    "    [X_train, decoder_input_train],  # Entrada do Encoder e Decoder\n",
    "    y_train_one_hot,                 # Saída esperada do Decoder\n",
    "    validation_data=([X_test, decoder_input_test], y_test_one_hot),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1  # Para ver o progresso do treinamento\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label=\"Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_sequence(encoder_model, decoder_model, input_seq, max_decoder_length, target_tokenizer):\n",
    "    # 1️⃣ Passar a entrada pelo encoder\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 2️⃣ Criar um array inicial para o decoder (apenas o token <START>)\n",
    "    target_seq = np.zeros((1, 1, num_classes))  # 1 batch, 1 timestep, num_classes\n",
    "    target_seq[0, 0, target_tokenizer.word_index['<START>']] = 1  # Definir <START>\n",
    "\n",
    "    decoded_sentence = \"\"\n",
    "    \n",
    "    for _ in range(max_decoder_length):\n",
    "        # 3️⃣ Fazer a predição de um token\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # 4️⃣ Escolher o token com maior probabilidade\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_word = target_tokenizer.index_word.get(sampled_token_index, \"\")\n",
    "\n",
    "        # 5️⃣ Se for <END>, para a geração\n",
    "        if sampled_word == \"<END>\":\n",
    "            break\n",
    "\n",
    "        decoded_sentence += \" \" + sampled_word\n",
    "\n",
    "        # 6️⃣ Atualizar a sequência de entrada do decoder com a nova palavra gerada\n",
    "        target_seq = np.zeros((1, 1, num_classes))\n",
    "        target_seq[0, 0, sampled_token_index] = 1\n",
    "\n",
    "        # 7️⃣ Atualizar os estados internos do decoder\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\drodm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\activations\\leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create encoder model for inference\n",
    "# Extract the encoder part of the model\n",
    "encoder_inputs = Input(shape=(seq_length, input_dim))\n",
    "x = Dense(embed_dim)(encoder_inputs)\n",
    "\n",
    "# Add encoder transformer layers (reusing the transformer_encoder from previous cells)\n",
    "for _ in range(2):\n",
    "    x = transformer_encoder(x, embed_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "encoder_outputs = x\n",
    "encoder_model = Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "# Create decoder model for inference\n",
    "decoder_inputs = Input(shape=(seq_length, num_classes))\n",
    "encoder_output_inputs = Input(shape=(seq_length, embed_dim))\n",
    "x = Dense(embed_dim)(decoder_inputs)\n",
    "\n",
    "# Add decoder transformer layers\n",
    "for _ in range(2):\n",
    "    x = transformer_decoder(x, encoder_output_inputs, embed_dim, num_heads, ff_dim, dropout_rate)\n",
    "\n",
    "decoder_outputs = Dense(64)(x)\n",
    "decoder_outputs = LeakyReLU(alpha=0.1)(decoder_outputs)\n",
    "decoder_outputs = Dense(num_classes, activation=\"softmax\")(decoder_outputs)\n",
    "\n",
    "# Final decoder model for inference\n",
    "decoder_model = Model([decoder_inputs, encoder_output_inputs], decoder_outputs)\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input sequence\n",
    "    encoder_output = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Start with an empty sequence\n",
    "    target_seq = np.zeros((1, seq_length, num_classes))\n",
    "    \n",
    "    # Set initial state (all zeros except for start position)\n",
    "    # For simplicity, we'll use 0 as the start token index\n",
    "    target_seq[0, 0, 0] = 1.0\n",
    "    \n",
    "    # Collect predictions\n",
    "    predicted_sequence = np.zeros((1, seq_length, num_classes))\n",
    "    \n",
    "    # Generate the sequence one step at a time\n",
    "    for i in range(seq_length):\n",
    "        # Predict next token\n",
    "        output = decoder_model.predict([target_seq, encoder_output])\n",
    "        \n",
    "        # Store prediction for this timestep\n",
    "        predicted_sequence[0, i] = output[0, i]\n",
    "        \n",
    "        # For next step prediction, feed the current output back as input\n",
    "        if i < seq_length - 1:\n",
    "            target_seq[0, i+1] = output[0, i]\n",
    "    \n",
    "    # Convert from one-hot encoding to class indices\n",
    "    predicted_indices = np.argmax(predicted_sequence[0], axis=-1)\n",
    "    \n",
    "    # Convert class indices to mudra names\n",
    "    mudra_names = [label_encoder.classes_[idx] for idx in predicted_indices]\n",
    "    \n",
    "    # Return the most common predicted mudra (majority vote)\n",
    "    from collections import Counter\n",
    "    most_common = Counter(mudra_names).most_common(1)[0][0]\n",
    "    \n",
    "    return most_common\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "Predicted: Unknown/Transition\n"
     ]
    }
   ],
   "source": [
    "test_input = X_test[100:101]  # Get a single input sequence\n",
    "output = decode_sequence(test_input)\n",
    "print(\"Predicted:\", output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model on multiple examples\n",
    "num_samples = 10\n",
    "\n",
    "print(\"Evaluating model on multiple test examples...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "correct_count = 0\n",
    "for i in range(num_samples):\n",
    "    # Get test input\n",
    "    test_input = X_test[i:i+1]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = decode_sequence(test_input)\n",
    "    \n",
    "    # Get true label (most common class in sequence)\n",
    "    true_labels = y_test[i]\n",
    "    unique_values, counts = np.unique(true_labels, return_counts=True)\n",
    "    most_common_idx = unique_values[np.argmax(counts)]\n",
    "    true_mudra = label_encoder.classes_[most_common_idx]\n",
    "    \n",
    "    # Check if prediction is correct\n",
    "    is_correct = prediction == true_mudra\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "    \n",
    "    # Display result\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  True Mudra: {true_mudra}\")\n",
    "    print(f\"  Predicted: {prediction}\")\n",
    "    print(f\"  {'✓ Correct' if is_correct else '✗ Incorrect'}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Display overall accuracy\n",
    "accuracy = correct_count / num_samples\n",
    "print(f\"Overall accuracy: {accuracy:.2f} ({correct_count}/{num_samples})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on multiple test examples...\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Example 1:\n",
      "  True Mudra: Uttarabodhi\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Example 2:\n",
      "  True Mudra: Unknown/Transition\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "Example 3:\n",
      "  True Mudra: Uttarabodhi\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Example 4:\n",
      "  True Mudra: Bhumisparsa\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Example 5:\n",
      "  True Mudra: Varada\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "Example 6:\n",
      "  True Mudra: Unknown/Transition\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Example 7:\n",
      "  True Mudra: Namaskara\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
      "Example 8:\n",
      "  True Mudra: Karana\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "Example 9:\n",
      "  True Mudra: Jnana\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "Example 10:\n",
      "  True Mudra: Namaskara\n",
      "  Predicted: Dhyana\n",
      "  ✗ Incorrect\n",
      "--------------------------------------------------\n",
      "Overall accuracy: 0.00 (0/10)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Test model on multiple examples\n",
    "num_samples = 10\n",
    "\n",
    "print(\"Evaluating model on multiple test examples...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "correct_count = 0\n",
    "for i in range(num_samples):\n",
    "    # Get test input\n",
    "    test_input = X_test[i:i+1]\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = decode_sequence(test_input)\n",
    "    \n",
    "    # Get true label (most common class in sequence)\n",
    "    true_labels = y_test[i]\n",
    "    unique_values, counts = np.unique(true_labels, return_counts=True)\n",
    "    most_common_idx = unique_values[np.argmax(counts)]\n",
    "    true_mudra = label_encoder.classes_[most_common_idx]\n",
    "    \n",
    "    # Check if prediction is correct\n",
    "    is_correct = prediction == true_mudra\n",
    "    if is_correct:\n",
    "        correct_count += 1\n",
    "    \n",
    "    # Display result\n",
    "    print(f\"Example {i+1}:\")\n",
    "    print(f\"  True Mudra: {true_mudra}\")\n",
    "    print(f\"  Predicted: {prediction}\")\n",
    "    print(f\"  {'✓ Correct' if is_correct else '✗ Incorrect'}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Display overall accuracy\n",
    "accuracy = correct_count / num_samples\n",
    "print(f\"Overall accuracy: {accuracy:.2f} ({correct_count}/{num_samples})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
